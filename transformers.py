# -*- coding: utf-8 -*-
"""transformers

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1vw6OVPHb1Os87yvE56R8CfNQeadM7P1w
"""
# i will send datasource here 
# from google.colab import drive
# drive.mount('/content/drive')

# ====== DATASET ======
import pandas as pd
from sklearn.model_selection import train_test_split

# ====== Config ======
csv_path = "/content/drive/My Drive/data_cnn/SAMPLE_RANDOM/OVERLAP_PAIRS.csv"
output_dir = "/content/drive/My Drive/data_cnn/SAMPLE_RANDOM/"  # Folder to save split CSVs
train_ratio = 0.7
val_ratio = 0.2
test_ratio = 0.1

# ====== Load Data ======
df = pd.read_csv(csv_path)

# ====== Shuffle and Split ======
train_df, temp_df = train_test_split(df, test_size=(1 - train_ratio), random_state=42, shuffle=True)
val_df, test_df = train_test_split(temp_df, test_size=test_ratio / (test_ratio + val_ratio), random_state=42)

# ====== Save Splits ======
train_df.to_csv(f"{output_dir}/train.csv", index=False)
val_df.to_csv(f"{output_dir}/val.csv", index=False)
test_df.to_csv(f"{output_dir}/test.csv", index=False)

print(f"Train samples: {len(train_df)}")
print(f"Validation samples: {len(val_df)}")
print(f"Test samples: {len(test_df)}")
print("Dataset split and saved.")




# ====== TRAINING ======
import numpy as np
from time import time
import torch
import torch.nn as nn
from torch.utils.data import Dataset, DataLoader
from transformers import AutoImageProcessor, SwinModel
from torchvision import transforms
from PIL import Image
import pandas as pd
import os
import matplotlib.pyplot as plt
from tqdm import tqdm
from sklearn.metrics import accuracy_score
import copy

# ====== Config ======
model_name = "microsoft/swin-tiny-patch4-window7-224"
batch_size = 16
num_epochs = 10
learning_rate = 1e-4
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# ====== DataFrame Setup ======
# CSV with columns: img1, img2, label
dataframe = pd.read_csv("/content/drive/My Drive/data_cnn/SAMPLE_RANDOM/OVERLAP_PAIRS.csv")  # Adjust path if needed


# ====== Image Preprocessing ======
processor = AutoImageProcessor.from_pretrained(model_name)
transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize(mean=processor.image_mean, std=processor.image_std)
])

# ====== Dataset Class ======
class OverlapDataset(Dataset):
    def __init__(self, csv_file, root_dir, transform=None):
        """
        Args:
            csv_file (str): Path to the CSV file with columns img1,img2,label.
            root_dir (str): Root directory containing the train/ or val/ images.
            transform (callable, optional): Optional transform to be applied on a sample.
        """
        self.data = pd.read_csv(csv_file)#.iloc[:5000].reset_index(drop=True) # для теста тока первые n_к строк
        #  по хорошему надо протестить на всем датасете но выглядит так будто model is overfitting
        self.root_dir = root_dir
        self.transform = transform

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        row = self.data.iloc[idx]
        img1_path = os.path.join(self.root_dir, row['img1'])
        img2_path = os.path.join(self.root_dir, row['img2'])

        img1 = Image.open(img1_path).convert("RGB")
        img2 = Image.open(img2_path).convert("RGB")
        label = torch.tensor(row['label'], dtype=torch.float32)

        if self.transform:
            img1 = self.transform(img1)
            img2 = self.transform(img2)

        return img1, img2, label


# ====== Model ======
class SwinSiamese(nn.Module):
    def __init__(self):
        super(SwinSiamese, self).__init__()
        self.swin = SwinModel.from_pretrained(model_name)
        for param in self.swin.parameters():
            param.requires_grad = False  # Freeze backbone for now

        hidden_size = self.swin.config.hidden_size
        self.fc = nn.Sequential(
            nn.Linear(hidden_size * 2, 256),
            nn.ReLU(),
            nn.Linear(256, 1),
            nn.Sigmoid()
        )

    def forward(self, img1, img2):
        emb1 = self.swin(pixel_values=img1).pooler_output
        emb2 = self.swin(pixel_values=img2).pooler_output
        combined = torch.cat([emb1, emb2], dim=1)
        return self.fc(combined)

# ====== Dataloader ======
train_csv = "/content/drive/My Drive/data_cnn/SAMPLE_RANDOM/train.csv"
val_csv = "/content/drive/My Drive/data_cnn/SAMPLE_RANDOM/val.csv"
test_csv = "/content/drive/My Drive/data_cnn/SAMPLE_RANDOM/test.csv"

img_dir = "/content/drive/My Drive/data_cnn/SAMPLE_RANDOM/IMAGES"


train_dataset = OverlapDataset(train_csv, root_dir=img_dir, transform=transform)
val_dataset = OverlapDataset(val_csv, root_dir=img_dir, transform=transform)
test_dataset = OverlapDataset(test_csv, root_dir=img_dir, transform=transform)

train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)
val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)
test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)

# ====== Model, Loss, Optimizer ======
model = SwinSiamese().to(device)
criterion = nn.BCELoss()
optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)


# ====== Training Loop + Validation ======
train_losses, val_losses = [], []
train_accuracies, val_accuracies = [], []
best_val_loss = float('inf')
best_model_wts = copy.deepcopy(model.state_dict())

for epoch in range(num_epochs):
    model.train()
    running_loss = 0.0
    correct = 0
    total = 0

    progress_bar = tqdm(train_loader, desc=f"Epoch [{epoch+1}/{num_epochs}]")

    for img1, img2, label in progress_bar:
        img1, img2, label = img1.to(device), img2.to(device), label.to(device)

        optimizer.zero_grad()
        output = model(img1, img2).squeeze()
        loss = criterion(output, label)
        loss.backward()
        optimizer.step()

        running_loss += loss.item()
        preds = (output > 0.5).float()
        correct += (preds == label).sum().item()
        total += label.size(0)

        progress_bar.set_postfix(loss=loss.item())

    avg_train_loss = running_loss / len(train_loader)
    train_accuracy = correct / total
    train_losses.append(avg_train_loss)
    train_accuracies.append(train_accuracy)

    # ====== Validation ======
    model.eval()
    val_loss = 0.0
    val_correct = 0
    val_total = 0
    with torch.no_grad():
        for img1, img2, label in val_loader:
            img1, img2, label = img1.to(device), img2.to(device), label.to(device)
            output = model(img1, img2).squeeze()
            loss = criterion(output, label)

            val_loss += loss.item()
            preds = (output > 0.5).float()
            val_correct += (preds == label).sum().item()
            val_total += label.size(0)

    avg_val_loss = val_loss / len(val_loader)
    val_accuracy = val_correct / val_total
    val_losses.append(avg_val_loss)
    val_accuracies.append(val_accuracy)

    print(f"Epoch [{epoch+1}/{num_epochs}], Train Loss: {avg_train_loss:.4f}, Train Acc: {train_accuracy:.4f}, Val Loss: {avg_val_loss:.4f}, Val Acc: {val_accuracy:.4f}")

    # Save best model
    if avg_val_loss < best_val_loss:
        best_val_loss = avg_val_loss
        best_model_wts = copy.deepcopy(model.state_dict())


# ====== Load 'Best' Model Before Test ======
model.load_state_dict(best_model_wts)


# ====== Test Evaluation ======
model.eval()
test_loss = 0.0
test_correct = 0
test_total = 0

with torch.no_grad():
    for img1, img2, label in tqdm(test_loader, desc="Testing"):
        img1, img2, label = img1.to(device), img2.to(device), label.to(device)
        output = model(img1, img2).squeeze()
        loss = criterion(output, label)

        test_loss += loss.item()
        preds = (output > 0.5).float()
        test_correct += (preds == label).sum().item()
        test_total += label.size(0)

avg_test_loss = test_loss / len(test_loader)
test_accuracy = test_correct / test_total
print(f"\nTest Loss: {avg_test_loss:.4f}, Test Accuracy: {test_accuracy:.4f}")

# ====== Plotting Loss & Accuracy ======
plt.figure(figsize=(12, 5))

plt.subplot(1, 2, 1)
plt.plot(train_losses, label="Train Loss")
plt.plot(val_losses, label="Val Loss")
plt.xlabel("Epoch")
plt.ylabel("Loss")
plt.title("Loss over Epochs")
plt.grid(True)
plt.legend()

plt.subplot(1, 2, 2)
plt.plot(train_accuracies, label="Train Acc")
plt.plot(val_accuracies, label="Val Acc")
plt.xlabel("Epoch")
plt.ylabel("Accuracy")
plt.title("Accuracy over Epochs")
plt.grid(True)
plt.legend()

plt.tight_layout()
plt.show()

# ====== Save Best Model ======
torch.save(model.state_dict(), "/content/drive/My Drive/data_cnn/models/swin_siamese_best.pth")
print("Model is saved")